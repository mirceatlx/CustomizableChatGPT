{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32ms:\\Weldie\\main.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/main.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     speak \u001b[39m=\u001b[39m Dispatch(\u001b[39m\"\u001b[39m\u001b[39mSAPI.SpVoice\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/main.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     speak\u001b[39m.\u001b[39mSpeak(text)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/Weldie/main.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m speak(talk_to_gpt(\u001b[39m\"\u001b[39;49m\u001b[39mhi gpt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/main.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# listen for 5 seconds feed it into gpt and speak the response\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/main.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcallback\u001b[39m(recognizer, audio):\n",
      "\u001b[1;32ms:\\Weldie\\main.ipynb Cell 1\u001b[0m in \u001b[0;36mspeak\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/main.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwin32com\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m Dispatch\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/main.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m speak \u001b[39m=\u001b[39m Dispatch(\u001b[39m\"\u001b[39m\u001b[39mSAPI.SpVoice\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/Weldie/main.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m speak\u001b[39m.\u001b[39;49mSpeak(text)\n",
      "File \u001b[1;32m<COMObject SAPI.SpVoice>:2\u001b[0m, in \u001b[0;36mSpeak\u001b[1;34m(self, Text, Flags)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "# print openai version\n",
    "\n",
    "def talk_to_gpt(s):\n",
    "    return openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. You can search our database by doing search(query here)>\"},\n",
    "            {\"role\": \"user\", \"content\": s},\n",
    "        ]\n",
    "    )['choices'][0]['message']['content']\n",
    "\n",
    "# text to speech\n",
    "def speak(text):\n",
    "    from win32com.client import Dispatch\n",
    "    speak = Dispatch(\"SAPI.SpVoice\")\n",
    "    speak.Speak(text)\n",
    "\n",
    "speak(talk_to_gpt(\"hi gpt\"))\n",
    "\n",
    "# listen for 5 seconds feed it into gpt and speak the response\n",
    "def callback(recognizer, audio):\n",
    "    try:\n",
    "        # this should stop earlier as the environment is very noisy\n",
    "        speech_as_text = recognizer.recognize_google(audio, language=\"en-US\", show_all=False)\n",
    "        print(speech_as_text)\n",
    "        if \"hey google\" in speech_as_text.lower():\n",
    "            # Perform your action here\n",
    "            print(\"Performing action...\")\n",
    "            speak(talk_to_gpt(speech_as_text))\n",
    "    except sr.UnknownValueError:\n",
    "        pass\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spokestack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32ms:\\Weldie\\frontend\\main.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# spokestack\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install spokestack --user\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspokestack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyaudio\u001b[39;00m \u001b[39mimport\u001b[39;00m PyAudioInput\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspokestack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivation_timeout\u001b[39;00m \u001b[39mimport\u001b[39;00m ActivationTimeout\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspokestack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyaudio\u001b[39;00m \u001b[39mimport\u001b[39;00m PyAudioInput\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spokestack'"
     ]
    }
   ],
   "source": [
    "# spokestack\n",
    "!pip install spokestack --user\n",
    "from spokestack.io.pyaudio import PyAudioInput\n",
    "from spokestack.activation_timeout import ActivationTimeout\n",
    "from spokestack.io.pyaudio import PyAudioInput\n",
    "from spokestack.pipeline import SpeechPipeline\n",
    "from spokestack.vad.webrtc import VoiceActivityDetector\n",
    "from spokestack.wakeword.tflite import WakewordTrigger\n",
    "from spokestack.asr.spokestack.speech_recognizer import SpeechRecognizer\n",
    "\n",
    "mic = PyAudioInput()\n",
    "vad = VoiceActivityDetector()\n",
    "wake = WakewordTrigger(\"path_to_tflite_model\")\n",
    "asr = SpeechRecognizer(\"spokestack_id\", \"spokestack_secret\")\n",
    "timeout = ActivationTimeout()\n",
    "\n",
    "\n",
    "pipeline = SpeechPipeline(mic, [vad, wake, asr, timeout])\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import openai, subprocess\n",
    "import pyaudio\n",
    "import wave\n",
    "messages = [{\"role\": \"system\", \"content\": 'You are a therapist. Respond to all input in 25 words or less.'}]\n",
    "\n",
    "def output_file_recording():\n",
    "\n",
    "\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = 5\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* recording\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"* done recording\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "def listen_for_5_seconds():\n",
    "    global messages\n",
    "    output_file_recording()\n",
    "    # listen for 5 seconds using the microphone with pyaudio\n",
    "    audio_file= open('output.wav', \"rb\")\n",
    "\n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "    print(transcript)\n",
    "    messages.append({\"role\": \"user\", \"content\": transcript[\"text\"]})\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "    print(response)\n",
    "    system_message = response[\"choices\"][0][\"message\"]\n",
    "    messages.append(system_message)\n",
    "\n",
    "    speak(system_message[\"content\"])\n",
    "    chat_transcript = \"\"\n",
    "    for message in messages:\n",
    "        if message['role'] != 'system':\n",
    "            chat_transcript += message['role'] + \": \" + message['content'] + \"\\n\\n\"\n",
    "\n",
    "    return chat_transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n",
      "{\n",
      "  \"text\": \"Hello GPT\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! How can I assist you today?\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677781619,\n",
      "  \"id\": \"chatcmpl-6phvnpFYmLBVECEZR0wYC8QzKicmX\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 11,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 42\n",
      "  }\n",
      "}\n",
      "* recording\n",
      "* done recording\n",
      "{\n",
      "  \"text\": \"Let's. Watch good.\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"I'm not sure what you mean. Can you please provide more information or clarify your request?\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677781639,\n",
      "  \"id\": \"chatcmpl-6phw7q7sZcT8Mgy4XZ6DWCiJvcVun\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 21,\n",
      "    \"prompt_tokens\": 56,\n",
      "    \"total_tokens\": 77\n",
      "  }\n",
      "}\n",
      "* recording\n",
      "* done recording\n",
      "{\n",
      "  \"text\": \"Computer, what do you want to do today?\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"As an AI language model, I don't have personal desires or needs. However, I am designed to assist and respond to your requests. How can I help you?\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677781660,\n",
      "  \"id\": \"chatcmpl-6phwSXjKW2G9Yo9GV11DCWlZriaAR\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 36,\n",
      "    \"prompt_tokens\": 95,\n",
      "    \"total_tokens\": 131\n",
      "  }\n",
      "}\n",
      "* recording\n",
      "* done recording\n",
      "{\n",
      "  \"text\": \"How does TU Delft rank for computer science?\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"TU Delft is a well-regarded university for computer science with a strong international reputation. It consistently ranks among the top universities for computer science globally.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677781683,\n",
      "  \"id\": \"chatcmpl-6phwpHZGshaqNFWl4VGWRXJCoRfcm\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 33,\n",
      "    \"prompt_tokens\": 150,\n",
      "    \"total_tokens\": 183\n",
      "  }\n",
      "}\n",
      "* recording\n",
      "* done recording\n",
      "{\n",
      "  \"text\": \"Are we better than MIT?\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"It's difficult to make a direct comparison between TU Delft and MIT, as both institutions have different strengths and areas of focus within computer science. However, both universities are highly respected in the field and have made significant contributions to computer science research and education.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677781707,\n",
      "  \"id\": \"chatcmpl-6phxDCfM7R1WAxBUVOYTtSZsiwyqz\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 54,\n",
      "    \"prompt_tokens\": 197,\n",
      "    \"total_tokens\": 251\n",
      "  }\n",
      "}\n",
      "* recording\n",
      "* done recording\n",
      "{\n",
      "  \"text\": \"The rate limiting issue, something, I don't know. Least me something. If you are, I can start looking for the FAQs.\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"I'm sorry, but I'm not sure what specific issue you are referring to. Can you please provide more information or clarify your request? As an AI language model, I'm here to assist you to the best of my abilities.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677781789,\n",
      "  \"id\": \"chatcmpl-6phyX8iC0xCqTcfXat6KgtHYa6JuU\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 49,\n",
      "    \"prompt_tokens\": 287,\n",
      "    \"total_tokens\": 336\n",
      "  }\n",
      "}\n",
      "* recording\n",
      "* done recording\n",
      "{\n",
      "  \"text\": \"Yeah, he has got to go to Papua New Guinea and then he can get there.\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"I'm sorry but the statement you provided does not seem to make sense. Can you please provide more context or clarify your request so I can help you better?\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677782130,\n",
      "  \"id\": \"chatcmpl-6pi42eyyTsfnKOamf115VxTwTZEUK\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 34,\n",
      "    \"prompt_tokens\": 362,\n",
      "    \"total_tokens\": 396\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32ms:\\Weldie\\frontend\\main.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m audio_stream \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mopen(\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                 rate\u001b[39m=\u001b[39mporcupine\u001b[39m.\u001b[39msample_rate,\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                 channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                 \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mpyaudio\u001b[39m.\u001b[39mpaInt16,\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                 \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                 frames_per_buffer\u001b[39m=\u001b[39mporcupine\u001b[39m.\u001b[39mframe_length)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     pcm \u001b[39m=\u001b[39m audio_stream\u001b[39m.\u001b[39;49mread(porcupine\u001b[39m.\u001b[39;49mframe_length)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     pcm \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack_from(\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m porcupine\u001b[39m.\u001b[39mframe_length, pcm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Weldie/frontend/main.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     keyword_index \u001b[39m=\u001b[39m porcupine\u001b[39m.\u001b[39mprocess(pcm)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import pyaudio\n",
    "import pvporcupine\n",
    "\n",
    "porcupine = None\n",
    "pa = None\n",
    "audio_stream = None\n",
    "\n",
    "try:\n",
    "    porcupine = pvporcupine.create(keywords=[\"computer\", \"jarvis\"], access_key=\"key here\")\n",
    "\n",
    "    pa = pyaudio.PyAudio()\n",
    "\n",
    "    audio_stream = pa.open(\n",
    "                    rate=porcupine.sample_rate,\n",
    "                    channels=1,\n",
    "                    format=pyaudio.paInt16,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=porcupine.frame_length)\n",
    "\n",
    "    while True:\n",
    "        pcm = audio_stream.read(porcupine.frame_length)\n",
    "        pcm = struct.unpack_from(\"h\" * porcupine.frame_length, pcm)\n",
    "\n",
    "        keyword_index = porcupine.process(pcm)\n",
    "\n",
    "        if keyword_index >= 0:\n",
    "            listen_for_5_seconds()\n",
    "            speak(\"Computer online\")\n",
    "except Exception as e:\n",
    "    print(\"somethignwent wrong\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
